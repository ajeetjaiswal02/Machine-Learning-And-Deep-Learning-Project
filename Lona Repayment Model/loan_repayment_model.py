# -*- coding: utf-8 -*-
"""Loan repayment Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18aOy1ouYh2cNUwlHMXm2UQHaLIef5WKa

IN THIS WE got a work from a loan giving Company who give loan to people as per the data we have to make the model to check whether or not the person will pay the loan back or not

## **frist we make just a simple Visualisation**
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

data_info = pd.read_csv('lending_club_info.csv')

data_info.head(5)

df = pd.read_csv('lending_club_loan_two.csv')

df.head()

sns.countplot(x='loan_status',data=df)

plt.figure(figsize=(12,5))
sns.distplot(df['loan_amnt'],kde=None)

corr = df.corr()

plt.figure(figsize=(12,9))
sns.heatmap(corr,annot=True)

sns.scatterplot(x='installment',y='loan_amnt',data=df)

sns.boxplot(x='loan_status',y='loan_amnt',data=df)

df.groupby('loan_status')['loan_amnt'].describe()

sorted(df['grade'].unique())

df['sub_grade'].unique()

plt.figure(figsize=(12,4))
sns.countplot(x='grade',data=df,hue='loan_status')

plt.figure(figsize=(12,4))
subgrade_order = sorted(df['sub_grade'].unique())
sns.countplot(x='sub_grade',data=df,order=subgrade_order,palette='coolwarm')

plt.figure(figsize=(12,4))
subgrade_order = sorted(df['sub_grade'].unique())
sns.countplot(x='sub_grade',data=df,order=subgrade_order,palette='coolwarm',hue='loan_status')

f_and_g = df[(df['grade']=='G') | (df['grade']=='F')]

plt.figure(figsize=(12,4))
subgrade_order = sorted(f_and_g['sub_grade'].unique())
sns.countplot(x='sub_grade',data=f_and_g,order=subgrade_order,palette='coolwarm',hue='loan_status')

df['loan_repaid'] = df['loan_status'].map({'Fully Paid':1,'Charged Off':0})

df[['loan_repaid','loan_status']]

df.corr()['loan_repaid'].sort_values().drop('loan_repaid').plot(kind='bar')

"""##**NOW WE DO DATA PRE PROCESSING**"""

df.head(3)

len(df)

df.isnull().sum()

100 * df.isnull().sum() / len(df)

df['emp_title'].nunique()

df['emp_title'].value_counts()

df = df.drop('emp_title',axis=1)

sorted(df['emp_length'].dropna().unique())

emp_length_order = ['< 1 year',
 '1 year',
 '2 years',
 '3 years',
 '4 years',
 '5 years',
 '6 years',
 '7 years',
 '8 years',
 '9 years',
 '10+ years'
 ]

plt.figure(figsize=(12,4))
sns.countplot(x='emp_length',data=df,order=emp_length_order)

emp_co = df[df['loan_status']=='Charged Off'].groupby('emp_length').count()['loan_status']

emp_fp = df[df['loan_status']=='Fully Paid'].groupby('emp_length').count()['loan_status']

emp__len = emp_co/(emp_co+emp_fp)

emp__len.plot(kind='bar')

df = df.drop('emp_length',axis=1)

df.isnull().sum()

df = df.drop('title',axis=1)

df['mort_acc'].value_counts()

df.corr()['mort_acc'].sort_values()

total_acc_average = df.groupby('total_acc').mean()['mort_acc']

def fill_mort_acc(total_acc,mort_acc):

  if np.isnan(mort_acc):
    return total_acc_average[total_acc]
  else:
    return mort_acc

df['mort_acc'] = df.apply(lambda x: fill_mort_acc(x['total_acc'], x['mort_acc']), axis=1)

df = df.dropna()

"""#**Categorical Variables and Dummy Variables
We're done working with the missing data! Now we just need to deal with the string values due to the categorical columns.

TASK: List all the columns that are currently non-numeric. 

Another very useful method call**
"""

df.select_dtypes(['object']).columns

df['term'].value_counts()

df['term'] = df['term'].apply(lambda term: int(term[:3]))

df['term'].iloc[0]

"""grade feature
TASK: We already know grade is part of sub_grade, so just drop the grade feature.
"""

df = df.drop('grade',axis=1)

dummies = pd.get_dummies(df['sub_grade'],drop_first=True)
df = pd.concat([df.drop('sub_grade',axis=1),dummies],axis=1)

dummies = pd.get_dummies(df[['verification_status', 'application_type','initial_list_status','purpose']],drop_first=True)
df = pd.concat([df.drop( ['verification_status', 'application_type','initial_list_status','purpose'],axis=1),dummies],axis=1)

df.columns

df['home_ownership'].value_counts()

df['home_ownership']=df['home_ownership'].replace(['NONE', 'ANY'], 'OTHER')

dummies = pd.get_dummies(df['home_ownership'],drop_first=True)
df = df.drop('home_ownership',axis=1)
df = pd.concat([df,dummies],axis=1)

df['zipcode'] = df['address'].apply(lambda address: address[-5:])

df['zipcode'].value_counts()

dummies = pd.get_dummies(df['zipcode'],drop_first=True)
df = pd.concat([df.drop('zipcode',axis=1),dummies],axis=1)

df = df.drop('address',axis=1)

df = df.drop('issue_d',axis=1)

df['earliest_cr_line'] = pd.to_datetime(df['earliest_cr_line'])

df['earliest_cr_line'] = df['earliest_cr_line'].apply(lambda date: date.year)

df['earliest_cr_line'].value_counts()

df.head(1)

from sklearn.model_selection import train_test_split

df = df.drop('loan_status',axis=1)

X = df.drop('loan_repaid',axis=1).values
y = df['loan_repaid'].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()

X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""**CREATING THE MODEL AND TRAINING**"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense,Dropout

model = Sequential()

model.add(Dense(78,activation='relu'))
model.add(Dropout(0.2))


model.add(Dense(39,activation='relu'))
model.add(Dropout(0.2))


model.add(Dense(19,activation='relu'))
model.add(Dropout(0.2))

model.add(Dense(1,activation='sigmoid'))

model.compile(loss='binary_crossentropy',optimizer='adam')

model.fit(x=X_train,y=y_train,epochs=25,batch_size=256,validation_data=(X_test,y_test))

losses = pd.DataFrame(model.history.history)

losses.plot()

from sklearn.metrics import classification_report,confusion_matrix

prediction = model.predict_classes(X_test)

print(classification_report(y_test,prediction))

print(confusion_matrix(y_test,prediction))

import random
random.seed(1)
random_ind = random.randint(0,len(df))

new_customer = df.drop('loan_repaid',axis=1).iloc[random_ind]
new_customer

new_customer = scaler.transform(new_customer.values.reshape(1,78))

model.predict_classes(new_customer)

df.iloc[random_ind]['loan_repaid']

from tensorflow.keras.models import load_model

model.save('loandata_model.h5')

